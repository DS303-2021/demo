{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0tlnCgfXltI"
   },
   "source": [
    "### Basic Neural Network\n",
    "\n",
    "A notebook to demonstrate a basic Neural Network using the Keras API. We'll train a 3 layer Neural Network for regression on the Boston Housing Price Prediction dataset.\n",
    "\n",
    "Run on [Google Colab](https://colab.research.google.com/drive/1BOelSpd4NZmFFDbZR0itCQMh8ilNbqBk?usp=sharing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "cellView": "code",
    "id": "0gGxrjZkXULK"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NAbSZiaoJ4z"
   },
   "source": [
    "Load and prepare the [Boston Housing Dataset](https://www.kaggle.com/c/boston-housing).\n",
    "\n",
    "This is a dataset taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
    "\n",
    "Samples contain 13 attributes of houses at different locations around the Boston suburbs in the late 1970s. Targets are the median values of the houses at a location (in k$).\n",
    "Variables in order:\n",
    "\n",
    "```\n",
    " CRIM     per capita crime rate by town\n",
    " ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    " INDUS    proportion of non-retail business acres per town\n",
    " CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    " NOX      nitric oxides concentration (parts per 10 million)\n",
    " RM       average number of rooms per dwelling\n",
    " AGE      proportion of owner-occupied units built prior to 1940\n",
    " DIS      weighted distances to five Boston employment centres\n",
    " RAD      index of accessibility to radial highways\n",
    " TAX      full-value property-tax rate per $10,000\n",
    " PTRATIO  pupil-teacher ratio by town\n",
    " B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    " LSTAT    % lower status of the population\n",
    " MEDV     Median value of owner-occupied homes in $1000's\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JqFRS6K07jJs",
    "outputId": "3d275a14-9fc8-4306-d0e1-446392ff6ceb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample feature vector before scaling:  [[9.1780e-02 0.0000e+00 4.0500e+00 0.0000e+00 5.1000e-01 6.4160e+00\n",
      "  8.4100e+01 2.6463e+00 5.0000e+00 2.9600e+02 1.6600e+01 3.9550e+02\n",
      "  9.0400e+00]]\n",
      "Sample feature vector after scaling:  [[-0.40544083 -0.4772386  -1.03573484 -0.27288841 -0.38295762  0.18146713\n",
      "   0.53502689 -0.53549508 -0.53418401 -0.66653121 -0.87342724  0.42641956\n",
      "  -0.51858417]]\n",
      "Number of training samples =  404\n"
     ]
    }
   ],
   "source": [
    "# Load from Keras Datasets\n",
    "(train_features, train_labels), (test_features, test_labels) = tf.keras.datasets.boston_housing.load_data(test_split=0.2, seed=42)\n",
    "print('Sample feature vector before scaling: ', train_features[:1])\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_features)\n",
    "train_features = scaler.transform(train_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "print('Sample feature vector after scaling: ', train_features[:1])\n",
    "\n",
    "train_samples, n_features = train_features.shape\n",
    "print('Number of training samples = ', train_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPZ68wASog_I"
   },
   "source": [
    "Build the `tf.keras` model architecture using the Sequential Class.\n",
    "\n",
    "Our model has two hidden layers with `20` and `10` neurons each and a final output layer to predict the final price. \n",
    "\n",
    "We are using the Mean Square Error loss for this regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "h3IKyzTCDNGo"
   },
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', name='hidden_layer1', kernel_initializer='he_normal', input_shape=(n_features,))) # hidden layer\n",
    "model.add(Dense(10, activation='relu', name='hidden_layer2', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, name='output')) # output layer \n",
    "\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMhUKx9wxt_k"
   },
   "source": [
    "Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "id": "15ialio5xpzd",
    "outputId": "82e14d7c-660b-43c4-db6c-98ea028f09e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden_layer1 (Dense)        (None, 20)                280       \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 501\n",
      "Trainable params: 501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.summary())\n",
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JB6A1vcigsIe"
   },
   "source": [
    "Model fitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqsMAYkPxW7Y",
    "outputId": "a631ad7f-34d0-4b39-cee7-fe97ac806d71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "11/11 [==============================] - 1s 17ms/step - loss: 581.7521 - val_loss: 649.5121\n",
      "Epoch 2/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 610.8183 - val_loss: 639.8145\n",
      "Epoch 3/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 551.0458 - val_loss: 630.4604\n",
      "Epoch 4/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 566.0229 - val_loss: 620.3592\n",
      "Epoch 5/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 571.9198 - val_loss: 608.9277\n",
      "Epoch 6/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 546.4432 - val_loss: 595.7844\n",
      "Epoch 7/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 539.4675 - val_loss: 580.1557\n",
      "Epoch 8/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 493.8185 - val_loss: 561.0392\n",
      "Epoch 9/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 511.5895 - val_loss: 538.8278\n",
      "Epoch 10/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 427.0088 - val_loss: 513.2638\n",
      "Epoch 11/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 492.1794 - val_loss: 484.8007\n",
      "Epoch 12/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 449.5311 - val_loss: 454.2315\n",
      "Epoch 13/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 398.8356 - val_loss: 420.3975\n",
      "Epoch 14/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 339.4711 - val_loss: 384.1403\n",
      "Epoch 15/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 310.8345 - val_loss: 345.0579\n",
      "Epoch 16/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 297.4636 - val_loss: 303.4092\n",
      "Epoch 17/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 255.1033 - val_loss: 262.0489\n",
      "Epoch 18/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 234.6802 - val_loss: 223.9303\n",
      "Epoch 19/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 188.1891 - val_loss: 187.9541\n",
      "Epoch 20/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 170.3027 - val_loss: 156.8874\n",
      "Epoch 21/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 142.1411 - val_loss: 129.1710\n",
      "Epoch 22/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 114.8394 - val_loss: 106.7992\n",
      "Epoch 23/800\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 122.6605 - val_loss: 90.7482\n",
      "Epoch 24/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 85.7533 - val_loss: 79.0256\n",
      "Epoch 25/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 72.1292 - val_loss: 70.7386\n",
      "Epoch 26/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 79.3638 - val_loss: 64.4147\n",
      "Epoch 27/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 69.9034 - val_loss: 59.3521\n",
      "Epoch 28/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 67.8517 - val_loss: 55.5286\n",
      "Epoch 29/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 64.8536 - val_loss: 52.3189\n",
      "Epoch 30/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.4081 - val_loss: 49.2981\n",
      "Epoch 31/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 51.9898 - val_loss: 47.0379\n",
      "Epoch 32/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 52.4577 - val_loss: 44.0276\n",
      "Epoch 33/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 50.9042 - val_loss: 40.9204\n",
      "Epoch 34/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 44.5082 - val_loss: 38.7619\n",
      "Epoch 35/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 44.9932 - val_loss: 36.9277\n",
      "Epoch 36/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 47.0258 - val_loss: 35.4410\n",
      "Epoch 37/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 38.5176 - val_loss: 34.1941\n",
      "Epoch 38/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 41.5222 - val_loss: 32.7614\n",
      "Epoch 39/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.3423 - val_loss: 31.4532\n",
      "Epoch 40/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.8941 - val_loss: 30.3076\n",
      "Epoch 41/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.3954 - val_loss: 29.2822\n",
      "Epoch 42/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 31.4933 - val_loss: 28.4095\n",
      "Epoch 43/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.1484 - val_loss: 27.5743\n",
      "Epoch 44/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.7801 - val_loss: 26.8954\n",
      "Epoch 45/800\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.6922 - val_loss: 26.2044\n",
      "Epoch 46/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.8308 - val_loss: 25.5964\n",
      "Epoch 47/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 28.2272 - val_loss: 24.8888\n",
      "Epoch 48/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 26.6915 - val_loss: 24.5272\n",
      "Epoch 49/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 28.6492 - val_loss: 24.0715\n",
      "Epoch 50/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 18.7620 - val_loss: 23.6319\n",
      "Epoch 51/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 27.0224 - val_loss: 23.1915\n",
      "Epoch 52/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 22.5556 - val_loss: 22.7861\n",
      "Epoch 53/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 27.2996 - val_loss: 22.5210\n",
      "Epoch 54/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.1335 - val_loss: 22.2996\n",
      "Epoch 55/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 27.5435 - val_loss: 22.0194\n",
      "Epoch 56/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 22.6501 - val_loss: 21.6474\n",
      "Epoch 57/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 18.3504 - val_loss: 21.3243\n",
      "Epoch 58/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 20.1199 - val_loss: 21.1115\n",
      "Epoch 59/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 23.9911 - val_loss: 20.9509\n",
      "Epoch 60/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 17.1087 - val_loss: 20.6679\n",
      "Epoch 61/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 20.5382 - val_loss: 20.4945\n",
      "Epoch 62/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 19.3534 - val_loss: 20.3235\n",
      "Epoch 63/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 17.2952 - val_loss: 20.0856\n",
      "Epoch 64/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 21.0454 - val_loss: 19.9145\n",
      "Epoch 65/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 22.6404 - val_loss: 19.9153\n",
      "Epoch 66/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 21.7410 - val_loss: 19.8360\n",
      "Epoch 67/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.2896 - val_loss: 19.7603\n",
      "Epoch 68/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.8755 - val_loss: 19.6702\n",
      "Epoch 69/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.4042 - val_loss: 19.5199\n",
      "Epoch 70/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 20.2855 - val_loss: 19.3694\n",
      "Epoch 71/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 19.4112 - val_loss: 19.1693\n",
      "Epoch 72/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 18.5020 - val_loss: 19.1420\n",
      "Epoch 73/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.4113 - val_loss: 19.0379\n",
      "Epoch 74/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 14.4099 - val_loss: 18.8699\n",
      "Epoch 75/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 15.4872 - val_loss: 18.7388\n",
      "Epoch 76/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 18.2352 - val_loss: 18.6124\n",
      "Epoch 77/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 14.9538 - val_loss: 18.6409\n",
      "Epoch 78/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 14.2231 - val_loss: 18.6164\n",
      "Epoch 79/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 16.0150 - val_loss: 18.5408\n",
      "Epoch 80/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 15.0130 - val_loss: 18.4471\n",
      "Epoch 81/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 15.2182 - val_loss: 18.4109\n",
      "Epoch 82/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 17.4181 - val_loss: 18.4680\n",
      "Epoch 83/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.3054 - val_loss: 18.4419\n",
      "Epoch 84/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.8797 - val_loss: 18.2805\n",
      "Epoch 85/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 13.9073 - val_loss: 18.2762\n",
      "Epoch 86/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 15.6521 - val_loss: 18.1263\n",
      "Epoch 87/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 14.5580 - val_loss: 17.8886\n",
      "Epoch 88/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.3277 - val_loss: 17.8736\n",
      "Epoch 89/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 15.2173 - val_loss: 17.7855\n",
      "Epoch 90/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 17.3727 - val_loss: 17.6963\n",
      "Epoch 91/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 17.2102 - val_loss: 17.6251\n",
      "Epoch 92/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 18.2139 - val_loss: 17.6200\n",
      "Epoch 93/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 19.4442 - val_loss: 17.7197\n",
      "Epoch 94/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.4234 - val_loss: 17.7293\n",
      "Epoch 95/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 13.4078 - val_loss: 17.6161\n",
      "Epoch 96/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.8885 - val_loss: 17.8526\n",
      "Epoch 97/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 14.2909 - val_loss: 17.7010\n",
      "Epoch 98/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 16.6650 - val_loss: 17.5888\n",
      "Epoch 99/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 16.4768 - val_loss: 17.4475\n",
      "Epoch 100/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 15.0807 - val_loss: 17.3957\n",
      "Epoch 101/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.9077 - val_loss: 17.1058\n",
      "Epoch 102/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.3009 - val_loss: 17.0133\n",
      "Epoch 103/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.4038 - val_loss: 17.0425\n",
      "Epoch 104/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.2382 - val_loss: 17.0151\n",
      "Epoch 105/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.8279 - val_loss: 17.1072\n",
      "Epoch 106/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 11.5672 - val_loss: 17.1201\n",
      "Epoch 107/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 17.6385 - val_loss: 17.0728\n",
      "Epoch 108/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.9794 - val_loss: 16.9684\n",
      "Epoch 109/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 12.2187 - val_loss: 16.9814\n",
      "Epoch 110/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 12.5642 - val_loss: 16.9597\n",
      "Epoch 111/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 12.9639 - val_loss: 16.9688\n",
      "Epoch 112/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 15.4315 - val_loss: 16.8363\n",
      "Epoch 113/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.9870 - val_loss: 16.7754\n",
      "Epoch 114/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.8824 - val_loss: 16.7791\n",
      "Epoch 115/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.2918 - val_loss: 16.8314\n",
      "Epoch 116/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 13.3336 - val_loss: 16.8911\n",
      "Epoch 117/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 16.4998 - val_loss: 16.8521\n",
      "Epoch 118/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.0517 - val_loss: 16.7615\n",
      "Epoch 119/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 15.6795 - val_loss: 16.6447\n",
      "Epoch 120/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.2381 - val_loss: 16.6704\n",
      "Epoch 121/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.9382 - val_loss: 16.7057\n",
      "Epoch 122/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 15.3436 - val_loss: 16.6456\n",
      "Epoch 123/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.1280 - val_loss: 16.4863\n",
      "Epoch 124/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 14.1960 - val_loss: 16.4873\n",
      "Epoch 125/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 12.6981 - val_loss: 16.4900\n",
      "Epoch 126/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 14.4433 - val_loss: 16.5039\n",
      "Epoch 127/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 16.6744 - val_loss: 16.5357\n",
      "Epoch 128/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 11.0742 - val_loss: 16.5708\n",
      "Epoch 129/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.8560 - val_loss: 16.4586\n",
      "Epoch 130/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 14.4109 - val_loss: 16.4755\n",
      "Epoch 131/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.3414 - val_loss: 16.5014\n",
      "Epoch 132/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.5906 - val_loss: 16.5018\n",
      "Epoch 133/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 13.7229 - val_loss: 16.4229\n",
      "Epoch 134/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 14.9687 - val_loss: 16.4995\n",
      "Epoch 135/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.1160 - val_loss: 16.4541\n",
      "Epoch 136/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.3758 - val_loss: 16.4124\n",
      "Epoch 137/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.7081 - val_loss: 16.3124\n",
      "Epoch 138/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.2555 - val_loss: 16.3753\n",
      "Epoch 139/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.4798 - val_loss: 16.4121\n",
      "Epoch 140/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.1638 - val_loss: 16.3794\n",
      "Epoch 141/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 13.7620 - val_loss: 16.3513\n",
      "Epoch 142/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.7686 - val_loss: 16.3932\n",
      "Epoch 143/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.0761 - val_loss: 16.4269\n",
      "Epoch 144/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.8189 - val_loss: 16.5486\n",
      "Epoch 145/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 11.2589 - val_loss: 16.3723\n",
      "Epoch 146/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.0812 - val_loss: 16.4543\n",
      "Epoch 147/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.8590 - val_loss: 16.6499\n",
      "Epoch 148/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 13.0120 - val_loss: 16.6543\n",
      "Epoch 149/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 10.6963 - val_loss: 16.6346\n",
      "Epoch 150/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.7133 - val_loss: 16.6096\n",
      "Epoch 151/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.3738 - val_loss: 16.5722\n",
      "Epoch 152/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.2537 - val_loss: 16.4904\n",
      "Epoch 153/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.2027 - val_loss: 16.4656\n",
      "Epoch 154/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.3233 - val_loss: 16.5227\n",
      "Epoch 155/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 12.5536 - val_loss: 16.5178\n",
      "Epoch 156/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.6728 - val_loss: 16.3469\n",
      "Epoch 157/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.3354 - val_loss: 16.4349\n",
      "Epoch 158/800\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 13.8725 - val_loss: 16.3558\n",
      "Epoch 159/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.2322 - val_loss: 16.3199\n",
      "Epoch 160/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.4816 - val_loss: 16.5268\n",
      "Epoch 161/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.0723 - val_loss: 16.5403\n",
      "Epoch 162/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 13.4073 - val_loss: 16.6328\n",
      "Epoch 163/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.7157 - val_loss: 16.6385\n",
      "Epoch 164/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.4168 - val_loss: 16.4767\n",
      "Epoch 165/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.4483 - val_loss: 16.4625\n",
      "Epoch 166/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.1203 - val_loss: 16.4370\n",
      "Epoch 167/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.3782 - val_loss: 16.2887\n",
      "Epoch 168/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.3255 - val_loss: 16.3130\n",
      "Epoch 169/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.6014 - val_loss: 16.3215\n",
      "Epoch 170/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.9310 - val_loss: 16.3737\n",
      "Epoch 171/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.4509 - val_loss: 16.3029\n",
      "Epoch 172/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.9527 - val_loss: 16.2944\n",
      "Epoch 173/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.0478 - val_loss: 16.2516\n",
      "Epoch 174/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.2209 - val_loss: 16.2100\n",
      "Epoch 175/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.1911 - val_loss: 16.2517\n",
      "Epoch 176/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 11.6253 - val_loss: 16.2167\n",
      "Epoch 177/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.2734 - val_loss: 16.3843\n",
      "Epoch 178/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.2986 - val_loss: 16.3267\n",
      "Epoch 179/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.2834 - val_loss: 16.1603\n",
      "Epoch 180/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 9.6227 - val_loss: 16.2121\n",
      "Epoch 181/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.0685 - val_loss: 16.1453\n",
      "Epoch 182/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 11.5104 - val_loss: 16.1305\n",
      "Epoch 183/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 12.7018 - val_loss: 16.1253\n",
      "Epoch 184/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.8658 - val_loss: 16.0128\n",
      "Epoch 185/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.3731 - val_loss: 15.9837\n",
      "Epoch 186/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 10.7421 - val_loss: 15.8898\n",
      "Epoch 187/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.4736 - val_loss: 15.9012\n",
      "Epoch 188/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.6644 - val_loss: 16.0083\n",
      "Epoch 189/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.7951 - val_loss: 16.2007\n",
      "Epoch 190/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.3685 - val_loss: 16.0829\n",
      "Epoch 191/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 9.9290 - val_loss: 16.0714\n",
      "Epoch 192/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 10.8974 - val_loss: 15.6579\n",
      "Epoch 193/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.3312 - val_loss: 15.5220\n",
      "Epoch 194/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.2728 - val_loss: 15.6217\n",
      "Epoch 195/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.2580 - val_loss: 15.8461\n",
      "Epoch 196/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.8716 - val_loss: 15.8619\n",
      "Epoch 197/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.6050 - val_loss: 15.7343\n",
      "Epoch 198/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 9.0144 - val_loss: 15.9077\n",
      "Epoch 199/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.1705 - val_loss: 16.0538\n",
      "Epoch 200/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.8331 - val_loss: 15.8750\n",
      "Epoch 201/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.8277 - val_loss: 15.8198\n",
      "Epoch 202/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 10.7961 - val_loss: 15.9436\n",
      "Epoch 203/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.1048 - val_loss: 15.8241\n",
      "Epoch 204/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.2302 - val_loss: 15.8602\n",
      "Epoch 205/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.3173 - val_loss: 15.8220\n",
      "Epoch 206/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.9699 - val_loss: 15.9550\n",
      "Epoch 207/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.7920 - val_loss: 16.1359\n",
      "Epoch 208/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.2300 - val_loss: 16.0662\n",
      "Epoch 209/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.4122 - val_loss: 15.8696\n",
      "Epoch 210/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.8064 - val_loss: 15.8635\n",
      "Epoch 211/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.5732 - val_loss: 15.9528\n",
      "Epoch 212/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.6609 - val_loss: 15.9735\n",
      "Epoch 213/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.6027 - val_loss: 15.8975\n",
      "Epoch 214/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.9996 - val_loss: 15.9069\n",
      "Epoch 215/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.4200 - val_loss: 15.9114\n",
      "Epoch 216/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.5621 - val_loss: 15.8538\n",
      "Epoch 217/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.8645 - val_loss: 15.7441\n",
      "Epoch 218/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.3977 - val_loss: 15.6825\n",
      "Epoch 219/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.5255 - val_loss: 15.6605\n",
      "Epoch 220/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.8981 - val_loss: 15.6521\n",
      "Epoch 221/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.2746 - val_loss: 15.6989\n",
      "Epoch 222/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.4333 - val_loss: 15.7164\n",
      "Epoch 223/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.0036 - val_loss: 15.6444\n",
      "Epoch 224/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.7618 - val_loss: 15.4209\n",
      "Epoch 225/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.1960 - val_loss: 15.5031\n",
      "Epoch 226/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.9718 - val_loss: 15.5928\n",
      "Epoch 227/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.7462 - val_loss: 15.7440\n",
      "Epoch 228/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 11.7886 - val_loss: 15.6906\n",
      "Epoch 229/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.4154 - val_loss: 15.5037\n",
      "Epoch 230/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.9158 - val_loss: 15.6542\n",
      "Epoch 231/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 8.6809 - val_loss: 15.5489\n",
      "Epoch 232/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.4451 - val_loss: 15.5471\n",
      "Epoch 233/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 9.9815 - val_loss: 15.5551\n",
      "Epoch 234/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.2532 - val_loss: 15.5645\n",
      "Epoch 235/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.0172 - val_loss: 15.4770\n",
      "Epoch 236/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.6879 - val_loss: 15.5790\n",
      "Epoch 237/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 10.3805 - val_loss: 15.4917\n",
      "Epoch 238/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.7127 - val_loss: 15.5348\n",
      "Epoch 239/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.4758 - val_loss: 15.5286\n",
      "Epoch 240/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.1913 - val_loss: 15.5982\n",
      "Epoch 241/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.3018 - val_loss: 15.4775\n",
      "Epoch 242/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.6179 - val_loss: 15.2754\n",
      "Epoch 243/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.1860 - val_loss: 15.2580\n",
      "Epoch 244/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 13.0532 - val_loss: 15.2864\n",
      "Epoch 245/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.7451 - val_loss: 15.1846\n",
      "Epoch 246/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.8408 - val_loss: 15.2440\n",
      "Epoch 247/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.4008 - val_loss: 15.3101\n",
      "Epoch 248/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.6523 - val_loss: 15.5893\n",
      "Epoch 249/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 9.6916 - val_loss: 15.3822\n",
      "Epoch 250/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.7284 - val_loss: 15.1422\n",
      "Epoch 251/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.3347 - val_loss: 15.1755\n",
      "Epoch 252/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.4631 - val_loss: 15.0099\n",
      "Epoch 253/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.0922 - val_loss: 15.2396\n",
      "Epoch 254/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.6351 - val_loss: 15.2473\n",
      "Epoch 255/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.6850 - val_loss: 15.1037\n",
      "Epoch 256/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.6300 - val_loss: 14.8991\n",
      "Epoch 257/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.7770 - val_loss: 14.9611\n",
      "Epoch 258/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 11.0080 - val_loss: 14.8247\n",
      "Epoch 259/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 9.1295 - val_loss: 14.8142\n",
      "Epoch 260/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 9.0392 - val_loss: 14.9707\n",
      "Epoch 261/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.8772 - val_loss: 14.9138\n",
      "Epoch 262/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.0838 - val_loss: 15.0216\n",
      "Epoch 263/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.5576 - val_loss: 15.4721\n",
      "Epoch 264/800\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 9.2039 - val_loss: 15.3881\n",
      "Epoch 265/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.4182 - val_loss: 15.2379\n",
      "Epoch 266/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.3046 - val_loss: 15.1556\n",
      "Epoch 267/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.4903 - val_loss: 15.1241\n",
      "Epoch 268/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.7729 - val_loss: 15.1693\n",
      "Epoch 269/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.0885 - val_loss: 15.0048\n",
      "Epoch 270/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.7190 - val_loss: 14.8533\n",
      "Epoch 271/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.7084 - val_loss: 14.7924\n",
      "Epoch 272/800\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 8.3175 - val_loss: 14.8291\n",
      "Epoch 273/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.1348 - val_loss: 14.7844\n",
      "Epoch 274/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.2687 - val_loss: 14.5178\n",
      "Epoch 275/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.7857 - val_loss: 14.4128\n",
      "Epoch 276/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.1561 - val_loss: 14.4837\n",
      "Epoch 277/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.7792 - val_loss: 14.5636\n",
      "Epoch 278/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.0132 - val_loss: 14.4847\n",
      "Epoch 279/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 8.9766 - val_loss: 14.5032\n",
      "Epoch 280/800\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 9.7648 - val_loss: 14.3172\n",
      "Epoch 281/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 8.2275 - val_loss: 14.3643\n",
      "Epoch 282/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.2905 - val_loss: 14.8545\n",
      "Epoch 283/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.3416 - val_loss: 14.7113\n",
      "Epoch 284/800\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 7.5165 - val_loss: 14.5718\n",
      "Epoch 285/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.2198 - val_loss: 14.6192\n",
      "Epoch 286/800\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 7.8898 - val_loss: 14.7780\n",
      "Epoch 287/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.1884 - val_loss: 14.7143\n",
      "Epoch 288/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.7561 - val_loss: 14.6531\n",
      "Epoch 289/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.3483 - val_loss: 14.6534\n",
      "Epoch 290/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.0434 - val_loss: 14.6056\n",
      "Epoch 291/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.4679 - val_loss: 14.5931\n",
      "Epoch 292/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.3762 - val_loss: 14.6634\n",
      "Epoch 293/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.6825 - val_loss: 14.7045\n",
      "Epoch 294/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.6084 - val_loss: 14.5551\n",
      "Epoch 295/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.4978 - val_loss: 14.4965\n",
      "Epoch 296/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.1874 - val_loss: 14.5264\n",
      "Epoch 297/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.6859 - val_loss: 14.5043\n",
      "Epoch 298/800\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 8.0537 - val_loss: 14.4240\n",
      "Epoch 299/800\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 8.4270 - val_loss: 14.3804\n",
      "Epoch 300/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.0444 - val_loss: 14.3883\n",
      "Epoch 301/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.5543 - val_loss: 14.4610\n",
      "Epoch 302/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 8.0532 - val_loss: 14.5530\n",
      "Epoch 303/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.2559 - val_loss: 14.4564\n",
      "Epoch 304/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.7423 - val_loss: 14.4404\n",
      "Epoch 305/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 9.4339 - val_loss: 14.4591\n",
      "Epoch 306/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.4919 - val_loss: 14.2843\n",
      "Epoch 307/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.8498 - val_loss: 14.1972\n",
      "Epoch 308/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.7521 - val_loss: 14.4166\n",
      "Epoch 309/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.5251 - val_loss: 14.6525\n",
      "Epoch 310/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.5115 - val_loss: 14.7377\n",
      "Epoch 311/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.5876 - val_loss: 14.5756\n",
      "Epoch 312/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.1007 - val_loss: 14.3583\n",
      "Epoch 313/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.0265 - val_loss: 14.3960\n",
      "Epoch 314/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.4884 - val_loss: 14.5959\n",
      "Epoch 315/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.8931 - val_loss: 14.4259\n",
      "Epoch 316/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.5705 - val_loss: 14.4111\n",
      "Epoch 317/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.2388 - val_loss: 14.5047\n",
      "Epoch 318/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.5838 - val_loss: 14.3949\n",
      "Epoch 319/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.4056 - val_loss: 14.3333\n",
      "Epoch 320/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.7546 - val_loss: 14.4309\n",
      "Epoch 321/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.3194 - val_loss: 14.3276\n",
      "Epoch 322/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.9607 - val_loss: 14.2656\n",
      "Epoch 323/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.5884 - val_loss: 14.1786\n",
      "Epoch 324/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.9416 - val_loss: 14.4084\n",
      "Epoch 325/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.0427 - val_loss: 14.1685\n",
      "Epoch 326/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.8459 - val_loss: 14.0032\n",
      "Epoch 327/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.9143 - val_loss: 14.0422\n",
      "Epoch 328/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.9591 - val_loss: 13.9577\n",
      "Epoch 329/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.6191 - val_loss: 14.0122\n",
      "Epoch 330/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.4327 - val_loss: 14.0807\n",
      "Epoch 331/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.2700 - val_loss: 14.0617\n",
      "Epoch 332/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.4061 - val_loss: 13.9055\n",
      "Epoch 333/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.4186 - val_loss: 13.9777\n",
      "Epoch 334/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.8037 - val_loss: 14.0473\n",
      "Epoch 335/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.7915 - val_loss: 14.0740\n",
      "Epoch 336/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.7760 - val_loss: 13.9896\n",
      "Epoch 337/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.7630 - val_loss: 13.9438\n",
      "Epoch 338/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.9614 - val_loss: 14.2561\n",
      "Epoch 339/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.6202 - val_loss: 13.9597\n",
      "Epoch 340/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 8.8191 - val_loss: 13.8984\n",
      "Epoch 341/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.4769 - val_loss: 13.7670\n",
      "Epoch 342/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.9033 - val_loss: 13.7682\n",
      "Epoch 343/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 7.1155 - val_loss: 13.8115\n",
      "Epoch 344/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.5458 - val_loss: 13.8726\n",
      "Epoch 345/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.0706 - val_loss: 13.8010\n",
      "Epoch 346/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.6538 - val_loss: 13.7747\n",
      "Epoch 347/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.6245 - val_loss: 13.7349\n",
      "Epoch 348/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.7079 - val_loss: 13.6788\n",
      "Epoch 349/800\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 7.3549 - val_loss: 13.6694\n",
      "Epoch 350/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.0468 - val_loss: 13.6890\n",
      "Epoch 351/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.2750 - val_loss: 13.8012\n",
      "Epoch 352/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.8010 - val_loss: 13.8116\n",
      "Epoch 353/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.4160 - val_loss: 13.8681\n",
      "Epoch 354/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.6792 - val_loss: 14.0259\n",
      "Epoch 355/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.3032 - val_loss: 14.0284\n",
      "Epoch 356/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.4186 - val_loss: 14.0140\n",
      "Epoch 357/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.7807 - val_loss: 13.8192\n",
      "Epoch 358/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.7854 - val_loss: 13.9361\n",
      "Epoch 359/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.7458 - val_loss: 13.6782\n",
      "Epoch 360/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.7200 - val_loss: 13.5426\n",
      "Epoch 361/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.9414 - val_loss: 13.5837\n",
      "Epoch 362/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.0042 - val_loss: 13.7310\n",
      "Epoch 363/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.8267 - val_loss: 13.6714\n",
      "Epoch 364/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.4728 - val_loss: 13.5845\n",
      "Epoch 365/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.7334 - val_loss: 13.7147\n",
      "Epoch 366/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.4475 - val_loss: 13.5918\n",
      "Epoch 367/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.3639 - val_loss: 13.5138\n",
      "Epoch 368/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.4610 - val_loss: 13.3995\n",
      "Epoch 369/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.7332 - val_loss: 13.3310\n",
      "Epoch 370/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.0390 - val_loss: 13.3526\n",
      "Epoch 371/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.7383 - val_loss: 13.7661\n",
      "Epoch 372/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.0640 - val_loss: 13.5775\n",
      "Epoch 373/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.1288 - val_loss: 13.5857\n",
      "Epoch 374/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.5840 - val_loss: 13.5243\n",
      "Epoch 375/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.6878 - val_loss: 13.3722\n",
      "Epoch 376/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.5060 - val_loss: 13.5362\n",
      "Epoch 377/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.1923 - val_loss: 13.4223\n",
      "Epoch 378/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.5396 - val_loss: 13.2149\n",
      "Epoch 379/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.2165 - val_loss: 13.2851\n",
      "Epoch 380/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 8.1346 - val_loss: 13.2216\n",
      "Epoch 381/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.2025 - val_loss: 13.2421\n",
      "Epoch 382/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.9844 - val_loss: 13.3310\n",
      "Epoch 383/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.9090 - val_loss: 13.2591\n",
      "Epoch 384/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.6106 - val_loss: 13.2802\n",
      "Epoch 385/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.8724 - val_loss: 13.4251\n",
      "Epoch 386/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.1225 - val_loss: 13.4756\n",
      "Epoch 387/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.4173 - val_loss: 13.3656\n",
      "Epoch 388/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.7411 - val_loss: 13.3691\n",
      "Epoch 389/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.3738 - val_loss: 13.4980\n",
      "Epoch 390/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.9867 - val_loss: 13.7632\n",
      "Epoch 391/800\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 9.3214 - val_loss: 13.5494\n",
      "Epoch 392/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.6319 - val_loss: 13.3008\n",
      "Epoch 393/800\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 6.2177 - val_loss: 13.3065\n",
      "Epoch 394/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.6165 - val_loss: 13.5101\n",
      "Epoch 395/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.7475 - val_loss: 13.5891\n",
      "Epoch 396/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.0523 - val_loss: 13.1713\n",
      "Epoch 397/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.8137 - val_loss: 13.0610\n",
      "Epoch 398/800\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 9.0040 - val_loss: 13.0695\n",
      "Epoch 399/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 9.1132 - val_loss: 13.1902\n",
      "Epoch 400/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.5156 - val_loss: 13.1543\n",
      "Epoch 401/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.1915 - val_loss: 13.1169\n",
      "Epoch 402/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.2081 - val_loss: 13.1780\n",
      "Epoch 403/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.8650 - val_loss: 13.1068\n",
      "Epoch 404/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.0952 - val_loss: 13.1380\n",
      "Epoch 405/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.7578 - val_loss: 13.1458\n",
      "Epoch 406/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.8117 - val_loss: 13.1322\n",
      "Epoch 407/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.2249 - val_loss: 13.2636\n",
      "Epoch 408/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.5218 - val_loss: 13.2843\n",
      "Epoch 409/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.6124 - val_loss: 13.3264\n",
      "Epoch 410/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.4467 - val_loss: 13.2029\n",
      "Epoch 411/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.7076 - val_loss: 13.2951\n",
      "Epoch 412/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.9192 - val_loss: 13.2173\n",
      "Epoch 413/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.9181 - val_loss: 13.1244\n",
      "Epoch 414/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.2018 - val_loss: 13.0830\n",
      "Epoch 415/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.5327 - val_loss: 13.1124\n",
      "Epoch 416/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.6316 - val_loss: 13.1298\n",
      "Epoch 417/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.7803 - val_loss: 13.1525\n",
      "Epoch 418/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.7303 - val_loss: 13.2239\n",
      "Epoch 419/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 6.1728 - val_loss: 13.1986\n",
      "Epoch 420/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.7753 - val_loss: 13.2331\n",
      "Epoch 421/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.2420 - val_loss: 13.1924\n",
      "Epoch 422/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.4726 - val_loss: 13.1979\n",
      "Epoch 423/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.7979 - val_loss: 13.1110\n",
      "Epoch 424/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.7335 - val_loss: 13.0986\n",
      "Epoch 425/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.4670 - val_loss: 13.0922\n",
      "Epoch 426/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.6271 - val_loss: 13.1623\n",
      "Epoch 427/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.2381 - val_loss: 13.2525\n",
      "Epoch 428/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.9768 - val_loss: 13.0986\n",
      "Epoch 429/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.0567 - val_loss: 12.9918\n",
      "Epoch 430/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.3948 - val_loss: 13.0276\n",
      "Epoch 431/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.5782 - val_loss: 12.9846\n",
      "Epoch 432/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.8534 - val_loss: 13.1217\n",
      "Epoch 433/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.6324 - val_loss: 13.1010\n",
      "Epoch 434/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.9334 - val_loss: 13.0099\n",
      "Epoch 435/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.5120 - val_loss: 12.9632\n",
      "Epoch 436/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.2420 - val_loss: 12.9074\n",
      "Epoch 437/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.5898 - val_loss: 12.9248\n",
      "Epoch 438/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.8252 - val_loss: 12.8379\n",
      "Epoch 439/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.6891 - val_loss: 12.7674\n",
      "Epoch 440/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.3732 - val_loss: 12.8425\n",
      "Epoch 441/800\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 5.9416 - val_loss: 12.8306\n",
      "Epoch 442/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.9793 - val_loss: 12.7882\n",
      "Epoch 443/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.9159 - val_loss: 12.9648\n",
      "Epoch 444/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.3472 - val_loss: 12.7006\n",
      "Epoch 445/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.3447 - val_loss: 12.7829\n",
      "Epoch 446/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.7856 - val_loss: 12.7971\n",
      "Epoch 447/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.6084 - val_loss: 12.7238\n",
      "Epoch 448/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.0931 - val_loss: 12.7530\n",
      "Epoch 449/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.2196 - val_loss: 13.0503\n",
      "Epoch 450/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.6179 - val_loss: 12.5987\n",
      "Epoch 451/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.0304 - val_loss: 12.9044\n",
      "Epoch 452/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.1578 - val_loss: 13.0923\n",
      "Epoch 453/800\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 7.7136 - val_loss: 12.9455\n",
      "Epoch 454/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.1021 - val_loss: 12.7746\n",
      "Epoch 455/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.6938 - val_loss: 12.7123\n",
      "Epoch 456/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.1935 - val_loss: 12.4961\n",
      "Epoch 457/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.3305 - val_loss: 12.2885\n",
      "Epoch 458/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 5.0484 - val_loss: 12.2534\n",
      "Epoch 459/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.9621 - val_loss: 12.2052\n",
      "Epoch 460/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.7353 - val_loss: 12.2557\n",
      "Epoch 461/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.7230 - val_loss: 12.4440\n",
      "Epoch 462/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.7532 - val_loss: 12.4644\n",
      "Epoch 463/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.2424 - val_loss: 12.4591\n",
      "Epoch 464/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.7236 - val_loss: 12.4485\n",
      "Epoch 465/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.2668 - val_loss: 12.5404\n",
      "Epoch 466/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.8564 - val_loss: 12.5157\n",
      "Epoch 467/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.0041 - val_loss: 12.3820\n",
      "Epoch 468/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 5.9274 - val_loss: 12.3246\n",
      "Epoch 469/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.1995 - val_loss: 12.4872\n",
      "Epoch 470/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.5682 - val_loss: 12.4328\n",
      "Epoch 471/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.4191 - val_loss: 12.4938\n",
      "Epoch 472/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.6618 - val_loss: 12.3865\n",
      "Epoch 473/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.1901 - val_loss: 12.3708\n",
      "Epoch 474/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.7104 - val_loss: 12.3092\n",
      "Epoch 475/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.1279 - val_loss: 12.2140\n",
      "Epoch 476/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.6152 - val_loss: 12.2314\n",
      "Epoch 477/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.6969 - val_loss: 12.3176\n",
      "Epoch 478/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.1791 - val_loss: 12.2221\n",
      "Epoch 479/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.1337 - val_loss: 12.2234\n",
      "Epoch 480/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.3165 - val_loss: 12.4597\n",
      "Epoch 481/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.8114 - val_loss: 12.4346\n",
      "Epoch 482/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.8443 - val_loss: 12.2702\n",
      "Epoch 483/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.9366 - val_loss: 12.2051\n",
      "Epoch 484/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.6535 - val_loss: 12.1286\n",
      "Epoch 485/800\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 5.4713 - val_loss: 11.9839\n",
      "Epoch 486/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.7170 - val_loss: 11.9414\n",
      "Epoch 487/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.1972 - val_loss: 11.9264\n",
      "Epoch 488/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.6986 - val_loss: 11.9443\n",
      "Epoch 489/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.1608 - val_loss: 11.9406\n",
      "Epoch 490/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.4431 - val_loss: 12.0052\n",
      "Epoch 491/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.6539 - val_loss: 12.4364\n",
      "Epoch 492/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.8958 - val_loss: 12.0901\n",
      "Epoch 493/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.2824 - val_loss: 12.2399\n",
      "Epoch 494/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.1830 - val_loss: 12.2796\n",
      "Epoch 495/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.6635 - val_loss: 12.1101\n",
      "Epoch 496/800\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 5.5575 - val_loss: 11.9272\n",
      "Epoch 497/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.5486 - val_loss: 11.9421\n",
      "Epoch 498/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.8359 - val_loss: 11.8677\n",
      "Epoch 499/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 6.3416 - val_loss: 11.9094\n",
      "Epoch 500/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 6.9628 - val_loss: 11.9507\n",
      "Epoch 501/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.3568 - val_loss: 11.9724\n",
      "Epoch 502/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.8593 - val_loss: 12.0542\n",
      "Epoch 503/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.7396 - val_loss: 12.0404\n",
      "Epoch 504/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.5589 - val_loss: 12.0268\n",
      "Epoch 505/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.5873 - val_loss: 12.2757\n",
      "Epoch 506/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 7.0992 - val_loss: 12.0445\n",
      "Epoch 507/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.5706 - val_loss: 11.9243\n",
      "Epoch 508/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.7011 - val_loss: 12.0195\n",
      "Epoch 509/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.1990 - val_loss: 12.2661\n",
      "Epoch 510/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 7.4110 - val_loss: 12.3709\n",
      "Epoch 511/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.8885 - val_loss: 12.2169\n",
      "Epoch 512/800\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 5.6151 - val_loss: 12.2413\n",
      "Epoch 513/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.0079 - val_loss: 12.0313\n",
      "Epoch 514/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.0515 - val_loss: 11.9293\n",
      "Epoch 515/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 5.8918 - val_loss: 11.7716\n",
      "Epoch 516/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.1347 - val_loss: 11.7830\n",
      "Epoch 517/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.6916 - val_loss: 11.8124\n",
      "Epoch 518/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.1608 - val_loss: 11.8125\n",
      "Epoch 519/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.3929 - val_loss: 11.7937\n",
      "Epoch 520/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.5758 - val_loss: 11.6167\n",
      "Epoch 521/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.3912 - val_loss: 11.4244\n",
      "Epoch 522/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.3229 - val_loss: 11.6531\n",
      "Epoch 523/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.2192 - val_loss: 11.6663\n",
      "Epoch 524/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.1014 - val_loss: 11.6810\n",
      "Epoch 525/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.0647 - val_loss: 11.6856\n",
      "Epoch 526/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.5746 - val_loss: 11.7659\n",
      "Epoch 527/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 6.1438 - val_loss: 11.8169\n",
      "Epoch 528/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.6056 - val_loss: 11.8628\n",
      "Epoch 529/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.6267 - val_loss: 11.7415\n",
      "Epoch 530/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 5.3599 - val_loss: 11.6953\n",
      "Epoch 531/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.5443 - val_loss: 11.6849\n",
      "Epoch 532/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.9677 - val_loss: 11.6516\n",
      "Epoch 533/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.8305 - val_loss: 11.6928\n",
      "Epoch 534/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.5946 - val_loss: 11.6957\n",
      "Epoch 535/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.8163 - val_loss: 11.6472\n",
      "Epoch 536/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.3310 - val_loss: 11.6829\n",
      "Epoch 537/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 5.9368 - val_loss: 11.6668\n",
      "Epoch 538/800\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 5.4294 - val_loss: 11.6994\n",
      "Epoch 539/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 5.7062 - val_loss: 11.6580\n",
      "Epoch 540/800\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 5.3015 - val_loss: 11.5926\n",
      "Epoch 541/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.6637 - val_loss: 11.4779\n",
      "Epoch 542/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.9044 - val_loss: 11.4564\n",
      "Epoch 543/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.3133 - val_loss: 11.6148\n",
      "Epoch 544/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.8425 - val_loss: 11.8386\n",
      "Epoch 545/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.4924 - val_loss: 11.9640\n",
      "Epoch 546/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.7129 - val_loss: 11.8231\n",
      "Epoch 547/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.3368 - val_loss: 11.7904\n",
      "Epoch 548/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.0297 - val_loss: 11.8372\n",
      "Epoch 549/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.3847 - val_loss: 11.8983\n",
      "Epoch 550/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.9015 - val_loss: 11.8561\n",
      "Epoch 551/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.7350 - val_loss: 11.7061\n",
      "Epoch 552/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.7450 - val_loss: 11.5714\n",
      "Epoch 553/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.6414 - val_loss: 11.1950\n",
      "Epoch 554/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.0470 - val_loss: 11.2907\n",
      "Epoch 555/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.8915 - val_loss: 11.4082\n",
      "Epoch 556/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.7604 - val_loss: 11.3843\n",
      "Epoch 557/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.7528 - val_loss: 11.3716\n",
      "Epoch 558/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.5819 - val_loss: 11.4243\n",
      "Epoch 559/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.5972 - val_loss: 11.4285\n",
      "Epoch 560/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.4384 - val_loss: 11.4897\n",
      "Epoch 561/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.9292 - val_loss: 11.5028\n",
      "Epoch 562/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.4400 - val_loss: 11.4257\n",
      "Epoch 563/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.6185 - val_loss: 11.3885\n",
      "Epoch 564/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.2627 - val_loss: 11.3527\n",
      "Epoch 565/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.9269 - val_loss: 11.4268\n",
      "Epoch 566/800\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 5.8809 - val_loss: 11.4550\n",
      "Epoch 567/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.9862 - val_loss: 11.4304\n",
      "Epoch 568/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.2537 - val_loss: 11.5514\n",
      "Epoch 569/800\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 5.3879 - val_loss: 11.5202\n",
      "Epoch 570/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.7552 - val_loss: 11.4496\n",
      "Epoch 571/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.4195 - val_loss: 11.4778\n",
      "Epoch 572/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.1013 - val_loss: 11.5623\n",
      "Epoch 573/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.3054 - val_loss: 11.7039\n",
      "Epoch 574/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.8079 - val_loss: 11.5450\n",
      "Epoch 575/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.2187 - val_loss: 11.1937\n",
      "Epoch 576/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.7454 - val_loss: 11.1239\n",
      "Epoch 577/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.7799 - val_loss: 11.0823\n",
      "Epoch 578/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.5300 - val_loss: 11.2627\n",
      "Epoch 579/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.8944 - val_loss: 11.2976\n",
      "Epoch 580/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.4395 - val_loss: 11.2795\n",
      "Epoch 581/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.4881 - val_loss: 11.2977\n",
      "Epoch 582/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.8693 - val_loss: 11.3553\n",
      "Epoch 583/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.6195 - val_loss: 11.3516\n",
      "Epoch 584/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.4180 - val_loss: 11.4425\n",
      "Epoch 585/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.7610 - val_loss: 11.3949\n",
      "Epoch 586/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 4.7012 - val_loss: 11.5614\n",
      "Epoch 587/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.9834 - val_loss: 11.5573\n",
      "Epoch 588/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 5.0750 - val_loss: 11.4053\n",
      "Epoch 589/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.0707 - val_loss: 11.3287\n",
      "Epoch 590/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.7384 - val_loss: 11.3059\n",
      "Epoch 591/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 4.3934 - val_loss: 11.2562\n",
      "Epoch 592/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.7198 - val_loss: 11.2283\n",
      "Epoch 593/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.5700 - val_loss: 11.2627\n",
      "Epoch 594/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.9615 - val_loss: 11.2398\n",
      "Epoch 595/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.1397 - val_loss: 11.1947\n",
      "Epoch 596/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.4982 - val_loss: 11.2165\n",
      "Epoch 597/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.7913 - val_loss: 11.3130\n",
      "Epoch 598/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.7909 - val_loss: 11.2310\n",
      "Epoch 599/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.4830 - val_loss: 11.2284\n",
      "Epoch 600/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.9681 - val_loss: 11.2888\n",
      "Epoch 601/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.1902 - val_loss: 11.3727\n",
      "Epoch 602/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.1503 - val_loss: 11.3625\n",
      "Epoch 603/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.1550 - val_loss: 11.4124\n",
      "Epoch 604/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.7963 - val_loss: 11.2001\n",
      "Epoch 605/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.6023 - val_loss: 11.2332\n",
      "Epoch 606/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.9136 - val_loss: 11.2268\n",
      "Epoch 607/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.0000 - val_loss: 11.1236\n",
      "Epoch 608/800\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 4.9001 - val_loss: 11.2004\n",
      "Epoch 609/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.4501 - val_loss: 11.2751\n",
      "Epoch 610/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.2884 - val_loss: 11.1863\n",
      "Epoch 611/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.2584 - val_loss: 11.1712\n",
      "Epoch 612/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.2911 - val_loss: 11.1783\n",
      "Epoch 613/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.3032 - val_loss: 11.1912\n",
      "Epoch 614/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.0499 - val_loss: 11.1977\n",
      "Epoch 615/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.3238 - val_loss: 11.1595\n",
      "Epoch 616/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.0817 - val_loss: 11.2961\n",
      "Epoch 617/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.7428 - val_loss: 11.4354\n",
      "Epoch 618/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.6351 - val_loss: 11.4096\n",
      "Epoch 619/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.3944 - val_loss: 11.3632\n",
      "Epoch 620/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.3472 - val_loss: 10.9958\n",
      "Epoch 621/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.8478 - val_loss: 10.8879\n",
      "Epoch 622/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.2781 - val_loss: 10.8711\n",
      "Epoch 623/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.5731 - val_loss: 10.9343\n",
      "Epoch 624/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.2351 - val_loss: 10.9500\n",
      "Epoch 625/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.8557 - val_loss: 10.9773\n",
      "Epoch 626/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.1147 - val_loss: 11.1891\n",
      "Epoch 627/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.5389 - val_loss: 11.5031\n",
      "Epoch 628/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.0089 - val_loss: 11.3144\n",
      "Epoch 629/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.3084 - val_loss: 11.3150\n",
      "Epoch 630/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.2369 - val_loss: 11.3239\n",
      "Epoch 631/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.6311 - val_loss: 11.3688\n",
      "Epoch 632/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.9760 - val_loss: 11.3211\n",
      "Epoch 633/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.6886 - val_loss: 11.1834\n",
      "Epoch 634/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.2489 - val_loss: 11.1269\n",
      "Epoch 635/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.6075 - val_loss: 11.0847\n",
      "Epoch 636/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.4503 - val_loss: 10.9669\n",
      "Epoch 637/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.3030 - val_loss: 10.9525\n",
      "Epoch 638/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.0644 - val_loss: 11.0248\n",
      "Epoch 639/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.9009 - val_loss: 11.0731\n",
      "Epoch 640/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.5416 - val_loss: 11.0423\n",
      "Epoch 641/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.0125 - val_loss: 10.9919\n",
      "Epoch 642/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.2879 - val_loss: 10.9628\n",
      "Epoch 643/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.2005 - val_loss: 11.1094\n",
      "Epoch 644/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 4.6115 - val_loss: 11.0664\n",
      "Epoch 645/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.6479 - val_loss: 10.8126\n",
      "Epoch 646/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.7899 - val_loss: 10.7541\n",
      "Epoch 647/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 3.9247 - val_loss: 10.9047\n",
      "Epoch 648/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.3627 - val_loss: 10.9694\n",
      "Epoch 649/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.2433 - val_loss: 10.8735\n",
      "Epoch 650/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.5073 - val_loss: 10.8504\n",
      "Epoch 651/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.4694 - val_loss: 11.0437\n",
      "Epoch 652/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.3484 - val_loss: 11.0456\n",
      "Epoch 653/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.2929 - val_loss: 11.0617\n",
      "Epoch 654/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.4543 - val_loss: 11.0004\n",
      "Epoch 655/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.6578 - val_loss: 10.9820\n",
      "Epoch 656/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.0080 - val_loss: 10.9929\n",
      "Epoch 657/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.8342 - val_loss: 11.1013\n",
      "Epoch 658/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.1973 - val_loss: 10.8611\n",
      "Epoch 659/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.7106 - val_loss: 10.8581\n",
      "Epoch 660/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.0545 - val_loss: 10.9137\n",
      "Epoch 661/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 3.9558 - val_loss: 11.0038\n",
      "Epoch 662/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 3.9946 - val_loss: 11.0260\n",
      "Epoch 663/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.5117 - val_loss: 11.0101\n",
      "Epoch 664/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 5.0605 - val_loss: 11.0408\n",
      "Epoch 665/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.7486 - val_loss: 11.0455\n",
      "Epoch 666/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.7393 - val_loss: 11.0413\n",
      "Epoch 667/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.8130 - val_loss: 11.0350\n",
      "Epoch 668/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.4053 - val_loss: 11.0276\n",
      "Epoch 669/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.5732 - val_loss: 10.9110\n",
      "Epoch 670/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 3.9088 - val_loss: 10.9383\n",
      "Epoch 671/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.6412 - val_loss: 10.9149\n",
      "Epoch 672/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.1226 - val_loss: 10.8846\n",
      "Epoch 673/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.0804 - val_loss: 10.9210\n",
      "Epoch 674/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.3658 - val_loss: 10.8958\n",
      "Epoch 675/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.5243 - val_loss: 10.8270\n",
      "Epoch 676/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.0428 - val_loss: 10.8059\n",
      "Epoch 677/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.8858 - val_loss: 10.8721\n",
      "Epoch 678/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.6385 - val_loss: 10.8873\n",
      "Epoch 679/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.5565 - val_loss: 10.8336\n",
      "Epoch 680/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.4653 - val_loss: 10.8048\n",
      "Epoch 681/800\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 4.9481 - val_loss: 10.9106\n",
      "Epoch 682/800\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 4.6003 - val_loss: 11.0151\n",
      "Epoch 683/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.8253 - val_loss: 10.9107\n",
      "Epoch 684/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.5047 - val_loss: 10.8728\n",
      "Epoch 685/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.4785 - val_loss: 10.8247\n",
      "Epoch 686/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.7669 - val_loss: 10.8606\n",
      "Epoch 687/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.7780 - val_loss: 10.8606\n",
      "Epoch 688/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.2852 - val_loss: 10.8481\n",
      "Epoch 689/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.4932 - val_loss: 10.8680\n",
      "Epoch 690/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.6873 - val_loss: 10.7939\n",
      "Epoch 691/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.4600 - val_loss: 10.6649\n",
      "Epoch 692/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.3420 - val_loss: 10.4858\n",
      "Epoch 693/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.5420 - val_loss: 10.7334\n",
      "Epoch 694/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.6879 - val_loss: 10.7788\n",
      "Epoch 695/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.3689 - val_loss: 10.7690\n",
      "Epoch 696/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.1756 - val_loss: 10.7878\n",
      "Epoch 697/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.9612 - val_loss: 10.8224\n",
      "Epoch 698/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.5991 - val_loss: 10.8374\n",
      "Epoch 699/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.3904 - val_loss: 10.9154\n",
      "Epoch 700/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.1389 - val_loss: 10.7392\n",
      "Epoch 701/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.7392 - val_loss: 10.7426\n",
      "Epoch 702/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.7947 - val_loss: 10.7625\n",
      "Epoch 703/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.7024 - val_loss: 10.8330\n",
      "Epoch 704/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.2917 - val_loss: 10.8192\n",
      "Epoch 705/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 3.8509 - val_loss: 10.9337\n",
      "Epoch 706/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.6901 - val_loss: 10.9807\n",
      "Epoch 707/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.6212 - val_loss: 10.9232\n",
      "Epoch 708/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.2379 - val_loss: 10.8140\n",
      "Epoch 709/800\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 4.0985 - val_loss: 10.8402\n",
      "Epoch 710/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.7022 - val_loss: 10.9111\n",
      "Epoch 711/800\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 3.9460 - val_loss: 10.9624\n",
      "Epoch 712/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.3353 - val_loss: 10.9846\n",
      "Epoch 713/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.2175 - val_loss: 10.9643\n",
      "Epoch 714/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.6998 - val_loss: 11.0365\n",
      "Epoch 715/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.6975 - val_loss: 11.0326\n",
      "Epoch 716/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.9749 - val_loss: 10.8876\n",
      "Epoch 717/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.9284 - val_loss: 10.8086\n",
      "Epoch 718/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.2839 - val_loss: 10.7613\n",
      "Epoch 719/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.4490 - val_loss: 10.6131\n",
      "Epoch 720/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.8298 - val_loss: 10.6088\n",
      "Epoch 721/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.0000 - val_loss: 10.6854\n",
      "Epoch 722/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.2160 - val_loss: 10.6888\n",
      "Epoch 723/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.8667 - val_loss: 10.7802\n",
      "Epoch 724/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.8210 - val_loss: 10.7030\n",
      "Epoch 725/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.7611 - val_loss: 10.7279\n",
      "Epoch 726/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.4673 - val_loss: 10.7463\n",
      "Epoch 727/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 5.0937 - val_loss: 10.7199\n",
      "Epoch 728/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.1986 - val_loss: 10.7014\n",
      "Epoch 729/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.0510 - val_loss: 10.7249\n",
      "Epoch 730/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.3109 - val_loss: 10.9384\n",
      "Epoch 731/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.0752 - val_loss: 10.9205\n",
      "Epoch 732/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.2272 - val_loss: 10.9680\n",
      "Epoch 733/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.6213 - val_loss: 11.0182\n",
      "Epoch 734/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.9251 - val_loss: 11.0933\n",
      "Epoch 735/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.2261 - val_loss: 11.1871\n",
      "Epoch 736/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.6483 - val_loss: 11.1323\n",
      "Epoch 737/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.8405 - val_loss: 11.0625\n",
      "Epoch 738/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 4.0032 - val_loss: 10.8923\n",
      "Epoch 739/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.8906 - val_loss: 10.8495\n",
      "Epoch 740/800\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.0050 - val_loss: 10.8593\n",
      "Epoch 741/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.5173 - val_loss: 10.8637\n",
      "Epoch 742/800\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 4.8276 - val_loss: 10.8217\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "\n",
    "# Use the Early Stopping Callback to terminate training if validation loss doesn't\n",
    "# improve within the specified epochs\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=50, verbose=0)\n",
    "\n",
    "history = model.fit(train_features, train_labels, epochs=800,\n",
    "                    batch_size=32, verbose=1,\n",
    "                    validation_split=0.2, callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ns0LjsZ0xI1"
   },
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Train and Validation loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "OsVqzN440XpF",
    "outputId": "a15cc075-332c-45d6-aca4-50a232dc792e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "\n",
    "def plot_history(hist):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error [Thousand Dollars$^2$]')\n",
    "    plt.plot(hist['epoch'], hist['loss'], label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_loss'], label = 'Val Error')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 50])\n",
    "    \n",
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6JTLCVg1ZZD"
   },
   "source": [
    "Performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01XESg3u0LQL",
    "outputId": "accb95cb-cb92-4bd2-b83e-a0487b264504"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 11.4114\n",
      "Root Mean Square Error on Test Data:  3.378083410015865\n"
     ]
    }
   ],
   "source": [
    "mse = model.evaluate(test_features, test_labels)\n",
    "print(\"Root Mean Square Error on Test Data: \", np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TUw2I-03NME"
   },
   "source": [
    "We are able to predict housing prices on the Boston test dataset within a Root Mean Square Error of 3.37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZ5W2c663cDM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "basic_NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "aiml",
   "language": "python",
   "name": "aiml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
